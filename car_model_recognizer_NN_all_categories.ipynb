{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and resize to standard dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import timeit\n",
    "\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "#  Convert Labels to one hot vector\n",
    "#########################################################################################\n",
    "\n",
    "\n",
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name = \"C\")\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(labels, C, axis=0)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "#  create mini batches \n",
    "#########################################################################################\n",
    "\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "#  load metadata of images \n",
    "#########################################################################################\n",
    "\n",
    "def load_image_metadata(filePath):\n",
    "    df = pd.read_csv(filePath)\n",
    "    images_metadata=  dict([(i,[a, b]) for i, a, b in zip(df.filename, df.Type, df.class_aggr)])\n",
    "    return images_metadata\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "#  load jpeg images from a folder into a list and standardize dimensions of the images \n",
    "#########################################################################################\n",
    "\n",
    "def load_images(folder, dim, images_metadata):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    classes = []\n",
    "    \n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        \n",
    "        img_resized =  cv2.resize(img, dim)\n",
    "        if img is not None:\n",
    "            images.append(img_resized)\n",
    "            filenames.append(filename)\n",
    "            classes.append(images_metadata[filename][1])\n",
    "    return (filenames, images, np.array(classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten and standarize entire data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "#  Flatten Reshape images to array of column vectors for each image \n",
    "#########################################################################################\n",
    "\n",
    "def flatten_dataset(my_images):\n",
    "    my_array = np.array(my_images, dtype=np.int32)\n",
    "    X_flatten = my_array.reshape(my_array.shape[0], -1).T \n",
    "    \n",
    "    # X_flatten = X_flatten / 255\n",
    "    return X_flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dev examples: m_dev = 6\n",
      "Height/Width of each image: num_px = 64\n",
      "Each image is of size: (64, 64, 3)\n",
      "dev_set_x shape: (12288, 6)\n",
      "000599.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xd7a7898>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBwEP8wTV6Q+XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcfb54e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define image height and width for standardiation\n",
    "\n",
    "num_px = 64\n",
    "dim = (num_px, num_px)\n",
    "\n",
    "# Load metadata of images\n",
    "img_metadata =  load_image_metadata(\"./data/meta-data/car_meta_data.csv\")\n",
    "\n",
    "# load images from the dev folder \n",
    "\n",
    "(dev_filenames, dev_images, dev_classes) = load_images(\"e:/car/car_ims/dev/\", dim, img_metadata)\n",
    "\n",
    "# get number of images\n",
    "m_dev  = len(dev_images)\n",
    "\n",
    "# reshape images to array of vectors \n",
    "dev_set_x = flatten_dataset(dev_images)\n",
    "\n",
    "# Print dev images details\n",
    "print (\"Number of dev examples: m_dev = \" + str(m_dev))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"dev_set_x shape: \" + str(dev_set_x.shape))\n",
    "\n",
    "\n",
    "# img1 = np.uint8(dev_set_x[:, index].reshape(64, 64, 3))\n",
    "\n",
    "# Diplay a sample image from Dev set\n",
    "index = 1\n",
    "\n",
    "print(dev_filenames[index])\n",
    "\n",
    "plt.imshow(dev_images[index])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_px = 224\n",
    "dim = (num_px, num_px)\n",
    "\n",
    "(train_filenames, train_images, train_classes) = load_images(\"e:/Car/car_ims/train/\", dim, img_metadata)\n",
    "(test_filenames, test_images, test_classes) = load_images(\"e:/Car/car_ims/test/\", dim, img_metadata)\n",
    "\n",
    "\n",
    "m_train  = len(train_images)\n",
    "m_test  = len(test_images)\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "\n",
    "index = 77\n",
    "\n",
    "plt.imshow(train_images[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 14562\n",
      "number of test examples = 1623\n",
      "X_train shape: (12288, 14562)\n",
      "Y_train shape: (15, 14562)\n",
      "X_test shape: (12288, 1623)\n",
      "Y_test shape: (15, 1623)\n"
     ]
    }
   ],
   "source": [
    "# Define number of classes\n",
    "C = 15\n",
    "\n",
    "# Flatten the training and test images\n",
    "X_train = flatten_dataset(train_images)\n",
    "X_test = flatten_dataset(test_images)\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = one_hot_matrix(train_classes, C)\n",
    "Y_test = one_hot_matrix(test_classes, C)\n",
    "\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 - Create placeholders¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_placeholders\n",
    "\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32, [n_x, None], name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None], name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 - Initializing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [50, 12288], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable(\"b1\", [50, 1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [C, 50], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable(\"b2\", [C, 1], initializer = tf.zeros_initializer())\n",
    "#     W3 = tf.get_variable(\"W3\", [C, 25], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "#     b3 = tf.get_variable(\"b3\", [C, 1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "#                   \"W3\": W3,\n",
    "#                   \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 - Forward propagation in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "#     W3 = parameters['W3']\n",
    "#     b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "#     A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "#     Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Compute cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 - Backward propagation & parameter updates\n",
    "This is where you become grateful to programming frameworks. All the backpropagation and the parameters update is taken care of in 1 line of code. It is very easy to incorporate this line in the model.\n",
    "After you compute the cost function. You will create an \"optimizer\" object. You have to call this object along with the cost when running the tf.session. When called, it will perform an optimization on the given cost with the chosen method and learning rate.\n",
    "For instance, for gradient descent the optimizer would be:\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "To make the optimization you would do:\n",
    "_ , c = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "This computes the backpropagation by passing through the tensorflow graph in the reverse order. From cost to inputs.\n",
    "Note When coding, we often use _ as a \"throwaway\" variable to store values that we won't need to use later. Here, _ takes on the evaluated value of optimizer, which we don't need (and c takes the value of the cost variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6 - Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 512, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    regularizer = 0.1 * sum(reg_losses)\n",
    "    cost = cost + regularizer\n",
    "   \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "                \n",
    "                minibatch_start_time = timeit.default_timer()\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 2 == 0:\n",
    "                correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "                print (\"Cost after epoch %i: %f; Training Accuracy: %f, Test Accuracy: %f\" % (epoch, epoch_cost, accuracy.eval({X: X_train, Y: Y_train}), accuracy.eval({X: X_test, Y: Y_test})))\n",
    "\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print(\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print(\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print(\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 2.264914; Training Accuracy: 0.267889, Test Accuracy: 0.268022\n",
      "Cost after epoch 2: 2.150352; Training Accuracy: 0.280387, Test Accuracy: 0.268022\n",
      "Cost after epoch 4: 2.119837; Training Accuracy: 0.290139, Test Accuracy: 0.276032\n",
      "Cost after epoch 6: 2.093790; Training Accuracy: 0.293778, Test Accuracy: 0.269254\n",
      "Cost after epoch 8: 2.078676; Training Accuracy: 0.292886, Test Accuracy: 0.264325\n",
      "Cost after epoch 10: 2.065122; Training Accuracy: 0.294190, Test Accuracy: 0.268022\n",
      "Cost after epoch 12: 2.053031; Training Accuracy: 0.308268, Test Accuracy: 0.279113\n",
      "Cost after epoch 14: 2.043188; Training Accuracy: 0.308955, Test Accuracy: 0.277264\n",
      "Cost after epoch 16: 2.031629; Training Accuracy: 0.312732, Test Accuracy: 0.279113\n",
      "Cost after epoch 18: 2.019093; Training Accuracy: 0.315959, Test Accuracy: 0.279729\n",
      "Cost after epoch 20: 2.011857; Training Accuracy: 0.320286, Test Accuracy: 0.278497\n",
      "Cost after epoch 22: 2.004661; Training Accuracy: 0.318432, Test Accuracy: 0.282193\n",
      "Cost after epoch 24: 1.995844; Training Accuracy: 0.320972, Test Accuracy: 0.276032\n",
      "Cost after epoch 26: 1.993421; Training Accuracy: 0.326604, Test Accuracy: 0.288355\n",
      "Cost after epoch 28: 1.980669; Training Accuracy: 0.332097, Test Accuracy: 0.283426\n",
      "Cost after epoch 30: 1.971880; Training Accuracy: 0.334295, Test Accuracy: 0.285890\n",
      "Cost after epoch 32: 1.967641; Training Accuracy: 0.313281, Test Accuracy: 0.293284\n",
      "Cost after epoch 34: 1.958029; Training Accuracy: 0.341711, Test Accuracy: 0.284658\n",
      "Cost after epoch 36: 1.945045; Training Accuracy: 0.337316, Test Accuracy: 0.279113\n",
      "Cost after epoch 38: 1.936261; Training Accuracy: 0.344389, Test Accuracy: 0.295749\n",
      "Cost after epoch 40: 1.930961; Training Accuracy: 0.350227, Test Accuracy: 0.285274\n",
      "Cost after epoch 42: 1.918993; Training Accuracy: 0.338278, Test Accuracy: 0.288971\n",
      "Cost after epoch 44: 1.907813; Training Accuracy: 0.351600, Test Accuracy: 0.292668\n",
      "Cost after epoch 46: 1.904748; Training Accuracy: 0.351600, Test Accuracy: 0.288971\n",
      "Cost after epoch 48: 1.894416; Training Accuracy: 0.359223, Test Accuracy: 0.280961\n",
      "Cost after epoch 50: 1.885323; Training Accuracy: 0.364030, Test Accuracy: 0.289587\n",
      "Cost after epoch 52: 1.884358; Training Accuracy: 0.366845, Test Accuracy: 0.292668\n",
      "Cost after epoch 54: 1.869488; Training Accuracy: 0.366365, Test Accuracy: 0.288971\n",
      "Cost after epoch 56: 1.866935; Training Accuracy: 0.370828, Test Accuracy: 0.287739\n",
      "Cost after epoch 58: 1.857487; Training Accuracy: 0.374262, Test Accuracy: 0.283426\n",
      "Cost after epoch 60: 1.850876; Training Accuracy: 0.376047, Test Accuracy: 0.285890\n",
      "Cost after epoch 62: 1.843631; Training Accuracy: 0.384769, Test Accuracy: 0.266790\n",
      "Cost after epoch 64: 1.830464; Training Accuracy: 0.382365, Test Accuracy: 0.287123\n",
      "Cost after epoch 66: 1.827405; Training Accuracy: 0.380168, Test Accuracy: 0.284658\n",
      "Cost after epoch 68: 1.821122; Training Accuracy: 0.388958, Test Accuracy: 0.280345\n",
      "Cost after epoch 70: 1.816053; Training Accuracy: 0.380099, Test Accuracy: 0.295132\n",
      "Cost after epoch 72: 1.806911; Training Accuracy: 0.394520, Test Accuracy: 0.290819\n",
      "Cost after epoch 74: 1.801999; Training Accuracy: 0.398915, Test Accuracy: 0.279113\n",
      "Cost after epoch 76: 1.796425; Training Accuracy: 0.399876, Test Accuracy: 0.281577\n",
      "Cost after epoch 78: 1.785987; Training Accuracy: 0.406400, Test Accuracy: 0.273567\n",
      "Cost after epoch 80: 1.779872; Training Accuracy: 0.398366, Test Accuracy: 0.272335\n",
      "Cost after epoch 82: 1.789049; Training Accuracy: 0.411207, Test Accuracy: 0.279729\n",
      "Cost after epoch 84: 1.773501; Training Accuracy: 0.405988, Test Accuracy: 0.289587\n",
      "Cost after epoch 86: 1.762552; Training Accuracy: 0.404203, Test Accuracy: 0.287739\n",
      "Cost after epoch 88: 1.763259; Training Accuracy: 0.409902, Test Accuracy: 0.287739\n",
      "Cost after epoch 90: 1.757229; Training Accuracy: 0.410177, Test Accuracy: 0.282810\n",
      "Cost after epoch 92: 1.753478; Training Accuracy: 0.417388, Test Accuracy: 0.279113\n",
      "Cost after epoch 94: 1.743054; Training Accuracy: 0.416358, Test Accuracy: 0.285274\n",
      "Cost after epoch 96: 1.737360; Training Accuracy: 0.420959, Test Accuracy: 0.282810\n",
      "Cost after epoch 98: 1.736710; Training Accuracy: 0.423568, Test Accuracy: 0.277264\n",
      "Cost after epoch 100: 1.723868; Training Accuracy: 0.428375, Test Accuracy: 0.284042\n",
      "Cost after epoch 102: 1.720012; Training Accuracy: 0.427276, Test Accuracy: 0.284042\n",
      "Cost after epoch 104: 1.722746; Training Accuracy: 0.425628, Test Accuracy: 0.271103\n",
      "Cost after epoch 106: 1.713760; Training Accuracy: 0.431877, Test Accuracy: 0.274800\n",
      "Cost after epoch 108: 1.706647; Training Accuracy: 0.436891, Test Accuracy: 0.278497\n",
      "Cost after epoch 110: 1.704954; Training Accuracy: 0.412031, Test Accuracy: 0.277880\n",
      "Cost after epoch 112: 1.700236; Training Accuracy: 0.424186, Test Accuracy: 0.284042\n",
      "Cost after epoch 114: 1.693012; Training Accuracy: 0.434075, Test Accuracy: 0.280345\n",
      "Cost after epoch 116: 1.682980; Training Accuracy: 0.446230, Test Accuracy: 0.272951\n",
      "Cost after epoch 118: 1.677977; Training Accuracy: 0.446161, Test Accuracy: 0.264941\n",
      "Cost after epoch 120: 1.693165; Training Accuracy: 0.418006, Test Accuracy: 0.276032\n",
      "Cost after epoch 122: 1.673099; Training Accuracy: 0.431465, Test Accuracy: 0.266174\n",
      "Cost after epoch 124: 1.666030; Training Accuracy: 0.443964, Test Accuracy: 0.285890\n",
      "Cost after epoch 126: 1.659882; Training Accuracy: 0.453784, Test Accuracy: 0.272951\n",
      "Cost after epoch 128: 1.655931; Training Accuracy: 0.452685, Test Accuracy: 0.276648\n",
      "Cost after epoch 130: 1.648970; Training Accuracy: 0.454333, Test Accuracy: 0.278497\n",
      "Cost after epoch 132: 1.655745; Training Accuracy: 0.437921, Test Accuracy: 0.276648\n",
      "Cost after epoch 134: 1.644739; Training Accuracy: 0.437646, Test Accuracy: 0.277264\n",
      "Cost after epoch 136: 1.633326; Training Accuracy: 0.448771, Test Accuracy: 0.274184\n",
      "Cost after epoch 138: 1.632987; Training Accuracy: 0.459072, Test Accuracy: 0.273567\n",
      "Cost after epoch 140: 1.633349; Training Accuracy: 0.454745, Test Accuracy: 0.263093\n",
      "Cost after epoch 142: 1.628440; Training Accuracy: 0.447878, Test Accuracy: 0.279729\n",
      "Cost after epoch 144: 1.616722; Training Accuracy: 0.445749, Test Accuracy: 0.277264\n",
      "Cost after epoch 146: 1.616628; Training Accuracy: 0.452960, Test Accuracy: 0.276648\n",
      "Cost after epoch 148: 1.606729; Training Accuracy: 0.467450, Test Accuracy: 0.269871\n",
      "Cost after epoch 150: 1.603923; Training Accuracy: 0.455707, Test Accuracy: 0.278497\n",
      "Cost after epoch 152: 1.596523; Training Accuracy: 0.477476, Test Accuracy: 0.271103\n",
      "Cost after epoch 154: 1.598783; Training Accuracy: 0.452204, Test Accuracy: 0.279113\n",
      "Cost after epoch 156: 1.589541; Training Accuracy: 0.470059, Test Accuracy: 0.271719\n",
      "Cost after epoch 158: 1.589823; Training Accuracy: 0.463604, Test Accuracy: 0.279113\n",
      "Cost after epoch 160: 1.583559; Training Accuracy: 0.488051, Test Accuracy: 0.263709\n",
      "Cost after epoch 162: 1.582357; Training Accuracy: 0.460926, Test Accuracy: 0.269254\n",
      "Cost after epoch 164: 1.577961; Training Accuracy: 0.483656, Test Accuracy: 0.268022\n",
      "Cost after epoch 166: 1.573406; Training Accuracy: 0.475278, Test Accuracy: 0.270487\n",
      "Cost after epoch 168: 1.565817; Training Accuracy: 0.486678, Test Accuracy: 0.268638\n",
      "Cost after epoch 170: 1.568377; Training Accuracy: 0.474729, Test Accuracy: 0.274800\n",
      "Cost after epoch 172: 1.557569; Training Accuracy: 0.478300, Test Accuracy: 0.271719\n",
      "Cost after epoch 174: 1.556015; Training Accuracy: 0.486815, Test Accuracy: 0.260628\n",
      "Cost after epoch 176: 1.554023; Training Accuracy: 0.492171, Test Accuracy: 0.271719\n",
      "Cost after epoch 178: 1.547296; Training Accuracy: 0.490592, Test Accuracy: 0.268022\n",
      "Cost after epoch 180: 1.542274; Training Accuracy: 0.505494, Test Accuracy: 0.260012\n",
      "Cost after epoch 182: 1.541633; Training Accuracy: 0.485373, Test Accuracy: 0.261861\n",
      "Cost after epoch 184: 1.540898; Training Accuracy: 0.491759, Test Accuracy: 0.279113\n",
      "Cost after epoch 186: 1.529021; Training Accuracy: 0.496154, Test Accuracy: 0.277880\n",
      "Cost after epoch 188: 1.526724; Training Accuracy: 0.495880, Test Accuracy: 0.263709\n",
      "Cost after epoch 190: 1.523969; Training Accuracy: 0.492583, Test Accuracy: 0.272951\n",
      "Cost after epoch 192: 1.522690; Training Accuracy: 0.502129, Test Accuracy: 0.260012\n",
      "Cost after epoch 194: 1.518208; Training Accuracy: 0.501579, Test Accuracy: 0.268022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 196: 1.512250; Training Accuracy: 0.511743, Test Accuracy: 0.256932\n",
      "Cost after epoch 198: 1.513590; Training Accuracy: 0.500069, Test Accuracy: 0.267406\n",
      "Cost after epoch 200: 1.507744; Training Accuracy: 0.507073, Test Accuracy: 0.263709\n",
      "Cost after epoch 202: 1.512266; Training Accuracy: 0.484824, Test Accuracy: 0.243376\n",
      "Cost after epoch 204: 1.501101; Training Accuracy: 0.527331, Test Accuracy: 0.261245\n",
      "Cost after epoch 206: 1.493158; Training Accuracy: 0.512498, Test Accuracy: 0.263093\n",
      "Cost after epoch 208: 1.488661; Training Accuracy: 0.511743, Test Accuracy: 0.263709\n",
      "Cost after epoch 210: 1.482657; Training Accuracy: 0.516893, Test Accuracy: 0.263093\n",
      "Cost after epoch 212: 1.484770; Training Accuracy: 0.476171, Test Accuracy: 0.270487\n",
      "Cost after epoch 214: 1.486331; Training Accuracy: 0.497116, Test Accuracy: 0.279113\n",
      "Cost after epoch 216: 1.491564; Training Accuracy: 0.525065, Test Accuracy: 0.264325\n",
      "Cost after epoch 218: 1.476701; Training Accuracy: 0.523554, Test Accuracy: 0.262477\n",
      "Cost after epoch 220: 1.476554; Training Accuracy: 0.506524, Test Accuracy: 0.266790\n",
      "Cost after epoch 222: 1.471904; Training Accuracy: 0.522456, Test Accuracy: 0.255083\n",
      "Cost after epoch 224: 1.466153; Training Accuracy: 0.523486, Test Accuracy: 0.260012\n",
      "Cost after epoch 226: 1.464811; Training Accuracy: 0.517923, Test Accuracy: 0.268022\n",
      "Cost after epoch 228: 1.454738; Training Accuracy: 0.521220, Test Accuracy: 0.273567\n",
      "Cost after epoch 230: 1.453773; Training Accuracy: 0.527812, Test Accuracy: 0.255083\n",
      "Cost after epoch 232: 1.455294; Training Accuracy: 0.531589, Test Accuracy: 0.250770\n",
      "Cost after epoch 234: 1.453791; Training Accuracy: 0.536053, Test Accuracy: 0.267406\n",
      "Cost after epoch 236: 1.443455; Training Accuracy: 0.506386, Test Accuracy: 0.272951\n",
      "Cost after epoch 238: 1.438800; Training Accuracy: 0.518473, Test Accuracy: 0.255083\n",
      "Cost after epoch 240: 1.450190; Training Accuracy: 0.497802, Test Accuracy: 0.268022\n",
      "Cost after epoch 242: 1.434698; Training Accuracy: 0.507348, Test Accuracy: 0.271719\n",
      "Cost after epoch 244: 1.429761; Training Accuracy: 0.531932, Test Accuracy: 0.265558\n",
      "Cost after epoch 246: 1.444294; Training Accuracy: 0.520945, Test Accuracy: 0.269254\n",
      "Cost after epoch 248: 1.430301; Training Accuracy: 0.519846, Test Accuracy: 0.271103\n",
      "Cost after epoch 250: 1.428076; Training Accuracy: 0.546148, Test Accuracy: 0.246457\n",
      "Cost after epoch 252: 1.425236; Training Accuracy: 0.527331, Test Accuracy: 0.262477\n",
      "Cost after epoch 254: 1.424063; Training Accuracy: 0.515245, Test Accuracy: 0.279113\n",
      "Cost after epoch 256: 1.427868; Training Accuracy: 0.540585, Test Accuracy: 0.265558\n",
      "Cost after epoch 258: 1.419410; Training Accuracy: 0.549169, Test Accuracy: 0.258780\n",
      "Cost after epoch 260: 1.408466; Training Accuracy: 0.553152, Test Accuracy: 0.243993\n",
      "Cost after epoch 262: 1.414588; Training Accuracy: 0.527263, Test Accuracy: 0.270487\n",
      "Cost after epoch 264: 1.402219; Training Accuracy: 0.545117, Test Accuracy: 0.248306\n",
      "Cost after epoch 266: 1.405261; Training Accuracy: 0.540928, Test Accuracy: 0.258780\n",
      "Cost after epoch 268: 1.398175; Training Accuracy: 0.544911, Test Accuracy: 0.261245\n",
      "Cost after epoch 270: 1.394335; Training Accuracy: 0.548826, Test Accuracy: 0.267406\n",
      "Cost after epoch 272: 1.392177; Training Accuracy: 0.535915, Test Accuracy: 0.267406\n",
      "Cost after epoch 274: 1.386191; Training Accuracy: 0.564002, Test Accuracy: 0.247073\n",
      "Cost after epoch 276: 1.408774; Training Accuracy: 0.550955, Test Accuracy: 0.261245\n",
      "Cost after epoch 278: 1.396040; Training Accuracy: 0.546491, Test Accuracy: 0.266790\n",
      "Cost after epoch 280: 1.384475; Training Accuracy: 0.559813, Test Accuracy: 0.257548\n",
      "Cost after epoch 282: 1.384935; Training Accuracy: 0.539692, Test Accuracy: 0.266174\n",
      "Cost after epoch 284: 1.378543; Training Accuracy: 0.537838, Test Accuracy: 0.257548\n",
      "Cost after epoch 286: 1.380844; Training Accuracy: 0.549924, Test Accuracy: 0.243993\n",
      "Cost after epoch 288: 1.385460; Training Accuracy: 0.558714, Test Accuracy: 0.262477\n",
      "Cost after epoch 290: 1.372295; Training Accuracy: 0.533924, Test Accuracy: 0.242760\n",
      "Cost after epoch 292: 1.359206; Training Accuracy: 0.556929, Test Accuracy: 0.266790\n",
      "Cost after epoch 294: 1.374910; Training Accuracy: 0.561461, Test Accuracy: 0.242760\n",
      "Cost after epoch 296: 1.366076; Training Accuracy: 0.525821, Test Accuracy: 0.274184\n",
      "Cost after epoch 298: 1.359621; Training Accuracy: 0.555556, Test Accuracy: 0.243993\n",
      "Cost after epoch 300: 1.373294; Training Accuracy: 0.576226, Test Accuracy: 0.250154\n",
      "Cost after epoch 302: 1.353430; Training Accuracy: 0.550405, Test Accuracy: 0.237215\n",
      "Cost after epoch 304: 1.354638; Training Accuracy: 0.569633, Test Accuracy: 0.252002\n",
      "Cost after epoch 306: 1.373565; Training Accuracy: 0.568260, Test Accuracy: 0.242760\n",
      "Cost after epoch 308: 1.353492; Training Accuracy: 0.564071, Test Accuracy: 0.255083\n",
      "Cost after epoch 310: 1.352688; Training Accuracy: 0.551229, Test Accuracy: 0.269254\n",
      "Cost after epoch 312: 1.342291; Training Accuracy: 0.562491, Test Accuracy: 0.256932\n",
      "Cost after epoch 314: 1.340541; Training Accuracy: 0.556654, Test Accuracy: 0.264325\n",
      "Cost after epoch 316: 1.339078; Training Accuracy: 0.512430, Test Accuracy: 0.277880\n",
      "Cost after epoch 318: 1.335032; Training Accuracy: 0.563315, Test Accuracy: 0.255699\n",
      "Cost after epoch 320: 1.332364; Training Accuracy: 0.567573, Test Accuracy: 0.258780\n",
      "Cost after epoch 322: 1.345360; Training Accuracy: 0.573204, Test Accuracy: 0.258164\n",
      "Cost after epoch 324: 1.331130; Training Accuracy: 0.558302, Test Accuracy: 0.250154\n",
      "Cost after epoch 326: 1.326036; Training Accuracy: 0.541272, Test Accuracy: 0.270487\n",
      "Cost after epoch 328: 1.327324; Training Accuracy: 0.567436, Test Accuracy: 0.255083\n",
      "Cost after epoch 330: 1.312240; Training Accuracy: 0.582956, Test Accuracy: 0.247689\n",
      "Cost after epoch 332: 1.324568; Training Accuracy: 0.583093, Test Accuracy: 0.252002\n",
      "Cost after epoch 334: 1.322366; Training Accuracy: 0.582338, Test Accuracy: 0.250770\n",
      "Cost after epoch 336: 1.316532; Training Accuracy: 0.523692, Test Accuracy: 0.272951\n",
      "Cost after epoch 338: 1.313720; Training Accuracy: 0.579316, Test Accuracy: 0.253851\n",
      "Cost after epoch 340: 1.312572; Training Accuracy: 0.568535, Test Accuracy: 0.253851\n",
      "Cost after epoch 342: 1.331615; Training Accuracy: 0.512018, Test Accuracy: 0.255699\n",
      "Cost after epoch 344: 1.306801; Training Accuracy: 0.582200, Test Accuracy: 0.263093\n",
      "Cost after epoch 346: 1.301312; Training Accuracy: 0.583711, Test Accuracy: 0.255083\n",
      "Cost after epoch 348: 1.316421; Training Accuracy: 0.562354, Test Accuracy: 0.246457\n",
      "Cost after epoch 350: 1.310252; Training Accuracy: 0.590372, Test Accuracy: 0.254467\n",
      "Cost after epoch 352: 1.312492; Training Accuracy: 0.577325, Test Accuracy: 0.234750\n",
      "Cost after epoch 354: 1.296505; Training Accuracy: 0.584604, Test Accuracy: 0.264941\n",
      "Cost after epoch 356: 1.294645; Training Accuracy: 0.589411, Test Accuracy: 0.266174\n",
      "Cost after epoch 358: 1.287310; Training Accuracy: 0.554937, Test Accuracy: 0.255699\n",
      "Cost after epoch 360: 1.300838; Training Accuracy: 0.579659, Test Accuracy: 0.259396\n",
      "Cost after epoch 362: 1.306123; Training Accuracy: 0.590990, Test Accuracy: 0.265558\n",
      "Cost after epoch 364: 1.283152; Training Accuracy: 0.563384, Test Accuracy: 0.258164\n",
      "Cost after epoch 366: 1.288715; Training Accuracy: 0.583368, Test Accuracy: 0.266790\n",
      "Cost after epoch 368: 1.272272; Training Accuracy: 0.588518, Test Accuracy: 0.258780\n",
      "Cost after epoch 370: 1.291478; Training Accuracy: 0.576088, Test Accuracy: 0.274800\n",
      "Cost after epoch 372: 1.281993; Training Accuracy: 0.591128, Test Accuracy: 0.258164\n",
      "Cost after epoch 374: 1.285399; Training Accuracy: 0.574097, Test Accuracy: 0.280961\n",
      "Cost after epoch 376: 1.273237; Training Accuracy: 0.603214, Test Accuracy: 0.256315\n",
      "Cost after epoch 378: 1.276169; Training Accuracy: 0.579179, Test Accuracy: 0.253851\n",
      "Cost after epoch 380: 1.285105; Training Accuracy: 0.583505, Test Accuracy: 0.227973\n",
      "Cost after epoch 382: 1.267427; Training Accuracy: 0.560157, Test Accuracy: 0.269871\n",
      "Cost after epoch 384: 1.267937; Training Accuracy: 0.588381, Test Accuracy: 0.255699\n",
      "Cost after epoch 386: 1.261170; Training Accuracy: 0.611248, Test Accuracy: 0.240296\n",
      "Cost after epoch 388: 1.252964; Training Accuracy: 0.595591, Test Accuracy: 0.259396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 390: 1.265834; Training Accuracy: 0.596553, Test Accuracy: 0.263093\n",
      "Cost after epoch 392: 1.257291; Training Accuracy: 0.586733, Test Accuracy: 0.255083\n",
      "Cost after epoch 394: 1.256859; Training Accuracy: 0.609120, Test Accuracy: 0.229205\n",
      "Cost after epoch 396: 1.257315; Training Accuracy: 0.589411, Test Accuracy: 0.270487\n",
      "Cost after epoch 398: 1.250744; Training Accuracy: 0.594492, Test Accuracy: 0.271103\n",
      "Cost after epoch 400: 1.254393; Training Accuracy: 0.600330, Test Accuracy: 0.250154\n",
      "Cost after epoch 402: 1.246473; Training Accuracy: 0.592226, Test Accuracy: 0.244609\n",
      "Cost after epoch 404: 1.247414; Training Accuracy: 0.600604, Test Accuracy: 0.264325\n",
      "Cost after epoch 406: 1.264393; Training Accuracy: 0.589548, Test Accuracy: 0.259396\n",
      "Cost after epoch 408: 1.245656; Training Accuracy: 0.583848, Test Accuracy: 0.263709\n",
      "Cost after epoch 410: 1.243092; Training Accuracy: 0.575676, Test Accuracy: 0.268022\n",
      "Cost after epoch 412: 1.251762; Training Accuracy: 0.611317, Test Accuracy: 0.246457\n",
      "Cost after epoch 414: 1.239852; Training Accuracy: 0.587557, Test Accuracy: 0.251386\n",
      "Cost after epoch 416: 1.239056; Training Accuracy: 0.616948, Test Accuracy: 0.236599\n",
      "Cost after epoch 418: 1.227319; Training Accuracy: 0.610562, Test Accuracy: 0.243376\n",
      "Cost after epoch 420: 1.230237; Training Accuracy: 0.618734, Test Accuracy: 0.235367\n",
      "Cost after epoch 422: 1.237986; Training Accuracy: 0.585290, Test Accuracy: 0.266174\n",
      "Cost after epoch 424: 1.236175; Training Accuracy: 0.616811, Test Accuracy: 0.246457\n",
      "Cost after epoch 426: 1.259318; Training Accuracy: 0.620313, Test Accuracy: 0.249538\n",
      "Cost after epoch 428: 1.246410; Training Accuracy: 0.532963, Test Accuracy: 0.276648\n",
      "Cost after epoch 430: 1.215575; Training Accuracy: 0.614270, Test Accuracy: 0.250770\n",
      "Cost after epoch 432: 1.218292; Training Accuracy: 0.615987, Test Accuracy: 0.264941\n",
      "Cost after epoch 434: 1.214445; Training Accuracy: 0.596415, Test Accuracy: 0.268022\n",
      "Cost after epoch 436: 1.220138; Training Accuracy: 0.612347, Test Accuracy: 0.256315\n",
      "Cost after epoch 438: 1.225830; Training Accuracy: 0.619626, Test Accuracy: 0.245225\n",
      "Cost after epoch 440: 1.223615; Training Accuracy: 0.619901, Test Accuracy: 0.251386\n",
      "Cost after epoch 442: 1.213841; Training Accuracy: 0.618253, Test Accuracy: 0.258164\n",
      "Cost after epoch 444: 1.222081; Training Accuracy: 0.613652, Test Accuracy: 0.255699\n",
      "Cost after epoch 446: 1.208698; Training Accuracy: 0.600879, Test Accuracy: 0.274184\n",
      "Cost after epoch 448: 1.210097; Training Accuracy: 0.595248, Test Accuracy: 0.255083\n",
      "Cost after epoch 450: 1.197545; Training Accuracy: 0.612416, Test Accuracy: 0.256315\n",
      "Cost after epoch 452: 1.203357; Training Accuracy: 0.584878, Test Accuracy: 0.274800\n",
      "Cost after epoch 454: 1.208424; Training Accuracy: 0.611111, Test Accuracy: 0.265558\n",
      "Cost after epoch 456: 1.206776; Training Accuracy: 0.613103, Test Accuracy: 0.237215\n",
      "Cost after epoch 458: 1.203439; Training Accuracy: 0.596965, Test Accuracy: 0.260012\n",
      "Cost after epoch 460: 1.223729; Training Accuracy: 0.569084, Test Accuracy: 0.285890\n",
      "Cost after epoch 462: 1.197595; Training Accuracy: 0.616330, Test Accuracy: 0.244609\n",
      "Cost after epoch 464: 1.191897; Training Accuracy: 0.625944, Test Accuracy: 0.250770\n",
      "Cost after epoch 466: 1.196574; Training Accuracy: 0.593394, Test Accuracy: 0.269254\n",
      "Cost after epoch 468: 1.184068; Training Accuracy: 0.611454, Test Accuracy: 0.269254\n",
      "Cost after epoch 470: 1.187529; Training Accuracy: 0.612141, Test Accuracy: 0.258164\n",
      "Cost after epoch 472: 1.193928; Training Accuracy: 0.615369, Test Accuracy: 0.256315\n",
      "Cost after epoch 474: 1.186070; Training Accuracy: 0.634322, Test Accuracy: 0.243376\n",
      "Cost after epoch 476: 1.202995; Training Accuracy: 0.612485, Test Accuracy: 0.265558\n",
      "Cost after epoch 478: 1.170685; Training Accuracy: 0.598819, Test Accuracy: 0.241528\n",
      "Cost after epoch 480: 1.187587; Training Accuracy: 0.626288, Test Accuracy: 0.251386\n",
      "Cost after epoch 482: 1.197304; Training Accuracy: 0.577531, Test Accuracy: 0.271719\n",
      "Cost after epoch 484: 1.177730; Training Accuracy: 0.612416, Test Accuracy: 0.258780\n",
      "Cost after epoch 486: 1.165518; Training Accuracy: 0.623678, Test Accuracy: 0.260012\n",
      "Cost after epoch 488: 1.177679; Training Accuracy: 0.642838, Test Accuracy: 0.260628\n",
      "Cost after epoch 490: 1.177692; Training Accuracy: 0.647233, Test Accuracy: 0.234750\n",
      "Cost after epoch 492: 1.162587; Training Accuracy: 0.634254, Test Accuracy: 0.250154\n",
      "Cost after epoch 494: 1.170605; Training Accuracy: 0.630889, Test Accuracy: 0.247689\n",
      "Cost after epoch 496: 1.161854; Training Accuracy: 0.632537, Test Accuracy: 0.233518\n",
      "Cost after epoch 498: 1.173529; Training Accuracy: 0.608364, Test Accuracy: 0.272951\n",
      "Cost after epoch 500: 1.161981; Training Accuracy: 0.637412, Test Accuracy: 0.249538\n",
      "Cost after epoch 502: 1.171302; Training Accuracy: 0.619558, Test Accuracy: 0.242144\n",
      "Cost after epoch 504: 1.153079; Training Accuracy: 0.603489, Test Accuracy: 0.272335\n",
      "Cost after epoch 506: 1.150510; Training Accuracy: 0.643799, Test Accuracy: 0.240912\n",
      "Cost after epoch 508: 1.168333; Training Accuracy: 0.578492, Test Accuracy: 0.280961\n",
      "Cost after epoch 510: 1.169382; Training Accuracy: 0.612691, Test Accuracy: 0.235983\n",
      "Cost after epoch 512: 1.154766; Training Accuracy: 0.641670, Test Accuracy: 0.219347\n",
      "Cost after epoch 514: 1.161651; Training Accuracy: 0.596415, Test Accuracy: 0.266174\n",
      "Cost after epoch 516: 1.163730; Training Accuracy: 0.614545, Test Accuracy: 0.259396\n",
      "Cost after epoch 518: 1.161122; Training Accuracy: 0.636932, Test Accuracy: 0.243993\n",
      "Cost after epoch 520: 1.157625; Training Accuracy: 0.628966, Test Accuracy: 0.255083\n",
      "Cost after epoch 522: 1.141690; Training Accuracy: 0.593806, Test Accuracy: 0.260012\n",
      "Cost after epoch 524: 1.154183; Training Accuracy: 0.577668, Test Accuracy: 0.272951\n",
      "Cost after epoch 526: 1.134281; Training Accuracy: 0.619832, Test Accuracy: 0.222428\n",
      "Cost after epoch 528: 1.158108; Training Accuracy: 0.634254, Test Accuracy: 0.249538\n",
      "Cost after epoch 530: 1.150023; Training Accuracy: 0.618184, Test Accuracy: 0.228589\n",
      "Cost after epoch 532: 1.130024; Training Accuracy: 0.638305, Test Accuracy: 0.227357\n",
      "Cost after epoch 534: 1.137720; Training Accuracy: 0.638030, Test Accuracy: 0.257548\n",
      "Cost after epoch 536: 1.140590; Training Accuracy: 0.627592, Test Accuracy: 0.239680\n",
      "Cost after epoch 538: 1.152825; Training Accuracy: 0.606029, Test Accuracy: 0.260012\n",
      "Cost after epoch 540: 1.134280; Training Accuracy: 0.645104, Test Accuracy: 0.262477\n",
      "Cost after epoch 542: 1.147856; Training Accuracy: 0.564071, Test Accuracy: 0.229205\n",
      "Cost after epoch 544: 1.140921; Training Accuracy: 0.642151, Test Accuracy: 0.258164\n",
      "Cost after epoch 546: 1.141590; Training Accuracy: 0.648469, Test Accuracy: 0.250154\n",
      "Cost after epoch 548: 1.131984; Training Accuracy: 0.643868, Test Accuracy: 0.258164\n",
      "Cost after epoch 550: 1.134961; Training Accuracy: 0.658426, Test Accuracy: 0.245225\n",
      "Cost after epoch 552: 1.125614; Training Accuracy: 0.656366, Test Accuracy: 0.246457\n",
      "Cost after epoch 554: 1.126288; Training Accuracy: 0.623884, Test Accuracy: 0.267406\n",
      "Cost after epoch 556: 1.119585; Training Accuracy: 0.636039, Test Accuracy: 0.260628\n",
      "Cost after epoch 558: 1.121469; Training Accuracy: 0.616674, Test Accuracy: 0.262477\n",
      "Cost after epoch 560: 1.123257; Training Accuracy: 0.633842, Test Accuracy: 0.261861\n",
      "Cost after epoch 562: 1.108268; Training Accuracy: 0.657327, Test Accuracy: 0.240296\n",
      "Cost after epoch 564: 1.137915; Training Accuracy: 0.633979, Test Accuracy: 0.248922\n",
      "Cost after epoch 566: 1.115700; Training Accuracy: 0.619146, Test Accuracy: 0.260012\n",
      "Cost after epoch 568: 1.117738; Training Accuracy: 0.637893, Test Accuracy: 0.250770\n",
      "Cost after epoch 570: 1.135039; Training Accuracy: 0.636176, Test Accuracy: 0.255699\n",
      "Cost after epoch 572: 1.127162; Training Accuracy: 0.626219, Test Accuracy: 0.250770\n",
      "Cost after epoch 574: 1.131156; Training Accuracy: 0.640365, Test Accuracy: 0.249538\n",
      "Cost after epoch 576: 1.126131; Training Accuracy: 0.656229, Test Accuracy: 0.242760\n",
      "Cost after epoch 578: 1.109439; Training Accuracy: 0.647439, Test Accuracy: 0.249538\n",
      "Cost after epoch 580: 1.123551; Training Accuracy: 0.635833, Test Accuracy: 0.247073\n",
      "Cost after epoch 582: 1.120981; Training Accuracy: 0.639267, Test Accuracy: 0.256932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 584: 1.094810; Training Accuracy: 0.642219, Test Accuracy: 0.259396\n",
      "Cost after epoch 586: 1.100743; Training Accuracy: 0.613377, Test Accuracy: 0.269254\n",
      "Cost after epoch 588: 1.109693; Training Accuracy: 0.618322, Test Accuracy: 0.274184\n",
      "Cost after epoch 590: 1.088249; Training Accuracy: 0.638511, Test Accuracy: 0.267406\n",
      "Cost after epoch 592: 1.097797; Training Accuracy: 0.626906, Test Accuracy: 0.235367\n",
      "Cost after epoch 594: 1.104337; Training Accuracy: 0.625532, Test Accuracy: 0.249538\n",
      "Cost after epoch 596: 1.122612; Training Accuracy: 0.616948, Test Accuracy: 0.253851\n",
      "Cost after epoch 598: 1.099732; Training Accuracy: 0.652589, Test Accuracy: 0.240296\n",
      "Cost after epoch 600: 1.111728; Training Accuracy: 0.638717, Test Accuracy: 0.266790\n",
      "Cost after epoch 602: 1.122234; Training Accuracy: 0.637344, Test Accuracy: 0.261861\n",
      "Cost after epoch 604: 1.095457; Training Accuracy: 0.648194, Test Accuracy: 0.252619\n",
      "Cost after epoch 606: 1.090150; Training Accuracy: 0.645859, Test Accuracy: 0.243993\n",
      "Cost after epoch 608: 1.088026; Training Accuracy: 0.659113, Test Accuracy: 0.229821\n",
      "Cost after epoch 610: 1.098297; Training Accuracy: 0.614751, Test Accuracy: 0.281577\n",
      "Cost after epoch 612: 1.082046; Training Accuracy: 0.655748, Test Accuracy: 0.240296\n",
      "Cost after epoch 614: 1.083289; Training Accuracy: 0.667491, Test Accuracy: 0.258780\n",
      "Cost after epoch 616: 1.084186; Training Accuracy: 0.609188, Test Accuracy: 0.266174\n",
      "Cost after epoch 618: 1.103803; Training Accuracy: 0.672366, Test Accuracy: 0.237831\n",
      "Cost after epoch 620: 1.077375; Training Accuracy: 0.656229, Test Accuracy: 0.248922\n",
      "Cost after epoch 622: 1.096107; Training Accuracy: 0.631575, Test Accuracy: 0.269254\n",
      "Cost after epoch 624: 1.097763; Training Accuracy: 0.653619, Test Accuracy: 0.229821\n",
      "Cost after epoch 626: 1.074937; Training Accuracy: 0.636588, Test Accuracy: 0.258164\n",
      "Cost after epoch 628: 1.088525; Training Accuracy: 0.673877, Test Accuracy: 0.252619\n",
      "Cost after epoch 630: 1.080472; Training Accuracy: 0.656297, Test Accuracy: 0.255699\n",
      "Cost after epoch 632: 1.062360; Training Accuracy: 0.645104, Test Accuracy: 0.249538\n",
      "Cost after epoch 634: 1.092875; Training Accuracy: 0.664401, Test Accuracy: 0.246457\n",
      "Cost after epoch 636: 1.070096; Training Accuracy: 0.628897, Test Accuracy: 0.200863\n",
      "Cost after epoch 638: 1.078492; Training Accuracy: 0.658014, Test Accuracy: 0.256315\n",
      "Cost after epoch 640: 1.076042; Training Accuracy: 0.668864, Test Accuracy: 0.230437\n",
      "Cost after epoch 642: 1.073976; Training Accuracy: 0.646134, Test Accuracy: 0.270487\n",
      "Cost after epoch 644: 1.078921; Training Accuracy: 0.656229, Test Accuracy: 0.238447\n",
      "Cost after epoch 646: 1.060753; Training Accuracy: 0.651971, Test Accuracy: 0.242760\n",
      "Cost after epoch 648: 1.070757; Training Accuracy: 0.658014, Test Accuracy: 0.229821\n",
      "Cost after epoch 650: 1.067650; Training Accuracy: 0.660830, Test Accuracy: 0.248922\n",
      "Cost after epoch 652: 1.079314; Training Accuracy: 0.656160, Test Accuracy: 0.237831\n",
      "Cost after epoch 654: 1.058267; Training Accuracy: 0.645928, Test Accuracy: 0.260012\n",
      "Cost after epoch 656: 1.055672; Training Accuracy: 0.641464, Test Accuracy: 0.246457\n",
      "Cost after epoch 658: 1.071919; Training Accuracy: 0.672366, Test Accuracy: 0.240912\n",
      "Cost after epoch 660: 1.061582; Training Accuracy: 0.662958, Test Accuracy: 0.258164\n",
      "Cost after epoch 662: 1.062548; Training Accuracy: 0.651834, Test Accuracy: 0.243376\n",
      "Cost after epoch 664: 1.048641; Training Accuracy: 0.659044, Test Accuracy: 0.246457\n",
      "Cost after epoch 666: 1.058188; Training Accuracy: 0.686101, Test Accuracy: 0.240912\n",
      "Cost after epoch 668: 1.061092; Training Accuracy: 0.588724, Test Accuracy: 0.261245\n",
      "Cost after epoch 670: 1.059481; Training Accuracy: 0.617566, Test Accuracy: 0.252002\n",
      "Cost after epoch 672: 1.067975; Training Accuracy: 0.655336, Test Accuracy: 0.264941\n",
      "Cost after epoch 674: 1.076177; Training Accuracy: 0.639129, Test Accuracy: 0.231670\n",
      "Cost after epoch 676: 1.066042; Training Accuracy: 0.620588, Test Accuracy: 0.237215\n",
      "Cost after epoch 678: 1.043273; Training Accuracy: 0.674633, Test Accuracy: 0.250154\n",
      "Cost after epoch 680: 1.081547; Training Accuracy: 0.590990, Test Accuracy: 0.265558\n",
      "Cost after epoch 682: 1.063576; Training Accuracy: 0.681225, Test Accuracy: 0.247073\n",
      "Cost after epoch 684: 1.052539; Training Accuracy: 0.683560, Test Accuracy: 0.214418\n",
      "Cost after epoch 686: 1.042299; Training Accuracy: 0.664194, Test Accuracy: 0.260012\n",
      "Cost after epoch 688: 1.030719; Training Accuracy: 0.633567, Test Accuracy: 0.272335\n",
      "Cost after epoch 690: 1.046155; Training Accuracy: 0.658357, Test Accuracy: 0.256315\n",
      "Cost after epoch 692: 1.048258; Training Accuracy: 0.672641, Test Accuracy: 0.242144\n",
      "Cost after epoch 694: 1.044655; Training Accuracy: 0.671542, Test Accuracy: 0.258164\n",
      "Cost after epoch 696: 1.075242; Training Accuracy: 0.664263, Test Accuracy: 0.253851\n",
      "Cost after epoch 698: 1.044308; Training Accuracy: 0.654168, Test Accuracy: 0.241528\n",
      "Cost after epoch 700: 1.054795; Training Accuracy: 0.645928, Test Accuracy: 0.245841\n",
      "Cost after epoch 702: 1.027512; Training Accuracy: 0.669208, Test Accuracy: 0.227973\n",
      "Cost after epoch 704: 1.041586; Training Accuracy: 0.662340, Test Accuracy: 0.234134\n",
      "Cost after epoch 706: 1.046403; Training Accuracy: 0.603695, Test Accuracy: 0.248922\n",
      "Cost after epoch 708: 1.066195; Training Accuracy: 0.613927, Test Accuracy: 0.219347\n",
      "Cost after epoch 710: 1.044642; Training Accuracy: 0.647576, Test Accuracy: 0.264941\n",
      "Cost after epoch 712: 1.034282; Training Accuracy: 0.666049, Test Accuracy: 0.250770\n",
      "Cost after epoch 714: 1.033864; Training Accuracy: 0.632743, Test Accuracy: 0.259396\n",
      "Cost after epoch 716: 1.037756; Training Accuracy: 0.660624, Test Accuracy: 0.235367\n",
      "Cost after epoch 718: 1.032267; Training Accuracy: 0.628966, Test Accuracy: 0.266790\n",
      "Cost after epoch 720: 1.031590; Training Accuracy: 0.657121, Test Accuracy: 0.241528\n",
      "Cost after epoch 722: 1.056700; Training Accuracy: 0.677036, Test Accuracy: 0.231054\n",
      "Cost after epoch 724: 1.029508; Training Accuracy: 0.688710, Test Accuracy: 0.247689\n",
      "Cost after epoch 726: 1.038570; Training Accuracy: 0.654168, Test Accuracy: 0.245841\n",
      "Cost after epoch 728: 1.041745; Training Accuracy: 0.672092, Test Accuracy: 0.230437\n",
      "Cost after epoch 730: 1.015144; Training Accuracy: 0.666735, Test Accuracy: 0.248306\n",
      "Cost after epoch 732: 1.004877; Training Accuracy: 0.653138, Test Accuracy: 0.253851\n",
      "Cost after epoch 734: 1.020669; Training Accuracy: 0.680538, Test Accuracy: 0.254467\n",
      "Cost after epoch 736: 1.031113; Training Accuracy: 0.645928, Test Accuracy: 0.245225\n",
      "Cost after epoch 738: 1.035870; Training Accuracy: 0.684109, Test Accuracy: 0.225508\n",
      "Cost after epoch 740: 1.027083; Training Accuracy: 0.692968, Test Accuracy: 0.255083\n",
      "Cost after epoch 742: 1.031357; Training Accuracy: 0.670718, Test Accuracy: 0.235367\n",
      "Cost after epoch 744: 1.027318; Training Accuracy: 0.638443, Test Accuracy: 0.256932\n",
      "Cost after epoch 746: 1.022110; Training Accuracy: 0.678684, Test Accuracy: 0.227973\n",
      "Cost after epoch 748: 1.014257; Training Accuracy: 0.672366, Test Accuracy: 0.257548\n",
      "Cost after epoch 750: 1.016418; Training Accuracy: 0.659319, Test Accuracy: 0.256315\n",
      "Cost after epoch 752: 1.006902; Training Accuracy: 0.676006, Test Accuracy: 0.249538\n",
      "Cost after epoch 754: 1.018500; Training Accuracy: 0.666529, Test Accuracy: 0.250770\n",
      "Cost after epoch 756: 1.008312; Training Accuracy: 0.695784, Test Accuracy: 0.230437\n",
      "Cost after epoch 758: 1.016354; Training Accuracy: 0.661860, Test Accuracy: 0.252619\n",
      "Cost after epoch 760: 1.013317; Training Accuracy: 0.673397, Test Accuracy: 0.255699\n",
      "Cost after epoch 762: 1.015790; Training Accuracy: 0.682324, Test Accuracy: 0.247689\n",
      "Cost after epoch 764: 1.007174; Training Accuracy: 0.644829, Test Accuracy: 0.266790\n",
      "Cost after epoch 766: 1.022875; Training Accuracy: 0.638855, Test Accuracy: 0.239063\n",
      "Cost after epoch 768: 1.002273; Training Accuracy: 0.703681, Test Accuracy: 0.250154\n",
      "Cost after epoch 770: 0.992590; Training Accuracy: 0.670993, Test Accuracy: 0.251386\n",
      "Cost after epoch 772: 1.027018; Training Accuracy: 0.690633, Test Accuracy: 0.250154\n",
      "Cost after epoch 774: 0.988225; Training Accuracy: 0.683079, Test Accuracy: 0.249538\n",
      "Cost after epoch 776: 1.020144; Training Accuracy: 0.661448, Test Accuracy: 0.215650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 778: 1.013561; Training Accuracy: 0.678478, Test Accuracy: 0.244609\n",
      "Cost after epoch 780: 1.005066; Training Accuracy: 0.704780, Test Accuracy: 0.239063\n",
      "Cost after epoch 782: 0.995062; Training Accuracy: 0.674839, Test Accuracy: 0.253851\n",
      "Cost after epoch 784: 1.014161; Training Accuracy: 0.693861, Test Accuracy: 0.229205\n",
      "Cost after epoch 786: 1.013955; Training Accuracy: 0.685757, Test Accuracy: 0.210105\n",
      "Cost after epoch 788: 1.018293; Training Accuracy: 0.662684, Test Accuracy: 0.249538\n",
      "Cost after epoch 790: 1.001706; Training Accuracy: 0.687337, Test Accuracy: 0.248922\n",
      "Cost after epoch 792: 1.040381; Training Accuracy: 0.670650, Test Accuracy: 0.251386\n",
      "Cost after epoch 794: 0.979794; Training Accuracy: 0.672572, Test Accuracy: 0.237215\n",
      "Cost after epoch 796: 1.009247; Training Accuracy: 0.658426, Test Accuracy: 0.244609\n",
      "Cost after epoch 798: 0.986834; Training Accuracy: 0.657671, Test Accuracy: 0.248922\n",
      "Cost after epoch 800: 1.030306; Training Accuracy: 0.652040, Test Accuracy: 0.233518\n",
      "Cost after epoch 802: 0.997095; Training Accuracy: 0.667697, Test Accuracy: 0.224276\n",
      "Cost after epoch 804: 0.980343; Training Accuracy: 0.694959, Test Accuracy: 0.252002\n",
      "Cost after epoch 806: 0.982670; Training Accuracy: 0.680950, Test Accuracy: 0.251386\n",
      "Cost after epoch 808: 1.001447; Training Accuracy: 0.683766, Test Accuracy: 0.248922\n",
      "Cost after epoch 810: 0.995299; Training Accuracy: 0.698462, Test Accuracy: 0.254467\n",
      "Cost after epoch 812: 1.014948; Training Accuracy: 0.683697, Test Accuracy: 0.219347\n",
      "Cost after epoch 814: 0.991775; Training Accuracy: 0.694685, Test Accuracy: 0.245225\n",
      "Cost after epoch 816: 0.993482; Training Accuracy: 0.704299, Test Accuracy: 0.242144\n",
      "Cost after epoch 818: 0.974860; Training Accuracy: 0.710754, Test Accuracy: 0.248306\n",
      "Cost after epoch 820: 0.980038; Training Accuracy: 0.669414, Test Accuracy: 0.255083\n",
      "Cost after epoch 822: 0.980298; Training Accuracy: 0.676006, Test Accuracy: 0.258164\n",
      "Cost after epoch 824: 0.984342; Training Accuracy: 0.665019, Test Accuracy: 0.257548\n",
      "Cost after epoch 826: 1.004403; Training Accuracy: 0.647026, Test Accuracy: 0.235367\n",
      "Cost after epoch 828: 1.050032; Training Accuracy: 0.655542, Test Accuracy: 0.232902\n",
      "Cost after epoch 830: 0.994624; Training Accuracy: 0.666323, Test Accuracy: 0.246457\n",
      "Cost after epoch 832: 0.958486; Training Accuracy: 0.684659, Test Accuracy: 0.256315\n",
      "Cost after epoch 834: 0.993716; Training Accuracy: 0.668315, Test Accuracy: 0.261861\n",
      "Cost after epoch 836: 0.983544; Training Accuracy: 0.672229, Test Accuracy: 0.235983\n",
      "Cost after epoch 838: 0.968436; Training Accuracy: 0.671748, Test Accuracy: 0.252002\n",
      "Cost after epoch 840: 0.953285; Training Accuracy: 0.661104, Test Accuracy: 0.258780\n",
      "Cost after epoch 842: 0.970352; Training Accuracy: 0.646408, Test Accuracy: 0.269254\n",
      "Cost after epoch 844: 0.983324; Training Accuracy: 0.700179, Test Accuracy: 0.247689\n",
      "Cost after epoch 846: 1.014429; Training Accuracy: 0.617566, Test Accuracy: 0.257548\n",
      "Cost after epoch 848: 0.969983; Training Accuracy: 0.684521, Test Accuracy: 0.209489\n",
      "Cost after epoch 850: 0.982978; Training Accuracy: 0.669620, Test Accuracy: 0.242760\n",
      "Cost after epoch 852: 0.990978; Training Accuracy: 0.663233, Test Accuracy: 0.238447\n",
      "Cost after epoch 854: 0.984627; Training Accuracy: 0.661173, Test Accuracy: 0.215650\n",
      "Cost after epoch 856: 1.015821; Training Accuracy: 0.702513, Test Accuracy: 0.225508\n",
      "Cost after epoch 858: 0.985756; Training Accuracy: 0.688642, Test Accuracy: 0.253235\n",
      "Cost after epoch 860: 0.951990; Training Accuracy: 0.710685, Test Accuracy: 0.242760\n",
      "Cost after epoch 862: 1.033350; Training Accuracy: 0.705741, Test Accuracy: 0.226741\n",
      "Cost after epoch 864: 0.987982; Training Accuracy: 0.701071, Test Accuracy: 0.203943\n",
      "Cost after epoch 866: 0.949171; Training Accuracy: 0.705741, Test Accuracy: 0.230437\n",
      "Cost after epoch 868: 0.969392; Training Accuracy: 0.704024, Test Accuracy: 0.251386\n",
      "Cost after epoch 870: 0.967642; Training Accuracy: 0.684315, Test Accuracy: 0.252002\n",
      "Cost after epoch 872: 0.960652; Training Accuracy: 0.708763, Test Accuracy: 0.232902\n",
      "Cost after epoch 874: 0.964453; Training Accuracy: 0.689260, Test Accuracy: 0.234750\n",
      "Cost after epoch 876: 0.982318; Training Accuracy: 0.640159, Test Accuracy: 0.243376\n",
      "Cost after epoch 878: 0.956196; Training Accuracy: 0.654443, Test Accuracy: 0.234750\n",
      "Cost after epoch 880: 0.969157; Training Accuracy: 0.683079, Test Accuracy: 0.256315\n",
      "Cost after epoch 882: 0.938256; Training Accuracy: 0.649705, Test Accuracy: 0.247689\n",
      "Cost after epoch 884: 0.963756; Training Accuracy: 0.713295, Test Accuracy: 0.231054\n",
      "Cost after epoch 886: 0.963191; Training Accuracy: 0.713844, Test Accuracy: 0.229821\n",
      "Cost after epoch 888: 0.963336; Training Accuracy: 0.650597, Test Accuracy: 0.238447\n",
      "Cost after epoch 890: 0.951128; Training Accuracy: 0.676487, Test Accuracy: 0.235983\n",
      "Cost after epoch 892: 0.949195; Training Accuracy: 0.640159, Test Accuracy: 0.262477\n",
      "Cost after epoch 894: 0.962609; Training Accuracy: 0.669894, Test Accuracy: 0.261861\n",
      "Cost after epoch 896: 0.953326; Training Accuracy: 0.696539, Test Accuracy: 0.240296\n",
      "Cost after epoch 898: 0.942115; Training Accuracy: 0.704986, Test Accuracy: 0.235367\n",
      "Cost after epoch 900: 0.962361; Training Accuracy: 0.705672, Test Accuracy: 0.233518\n",
      "Cost after epoch 902: 0.933957; Training Accuracy: 0.676143, Test Accuracy: 0.217498\n",
      "Cost after epoch 904: 0.961712; Training Accuracy: 0.696196, Test Accuracy: 0.240912\n",
      "Cost after epoch 906: 0.982945; Training Accuracy: 0.702101, Test Accuracy: 0.226124\n",
      "Cost after epoch 908: 0.939020; Training Accuracy: 0.661928, Test Accuracy: 0.211337\n",
      "Cost after epoch 910: 0.990190; Training Accuracy: 0.685895, Test Accuracy: 0.242760\n",
      "Cost after epoch 912: 0.936781; Training Accuracy: 0.685071, Test Accuracy: 0.249538\n",
      "Cost after epoch 914: 0.948936; Training Accuracy: 0.664744, Test Accuracy: 0.261245\n",
      "Cost after epoch 916: 0.943098; Training Accuracy: 0.657533, Test Accuracy: 0.227357\n",
      "Cost after epoch 918: 0.949365; Training Accuracy: 0.689466, Test Accuracy: 0.232286\n",
      "Cost after epoch 920: 0.959168; Training Accuracy: 0.688230, Test Accuracy: 0.234134\n",
      "Cost after epoch 922: 0.966158; Training Accuracy: 0.692144, Test Accuracy: 0.248922\n",
      "Cost after epoch 924: 0.954419; Training Accuracy: 0.687062, Test Accuracy: 0.254467\n",
      "Cost after epoch 926: 0.957663; Training Accuracy: 0.692556, Test Accuracy: 0.232286\n",
      "Cost after epoch 928: 0.973045; Training Accuracy: 0.672435, Test Accuracy: 0.226124\n",
      "Cost after epoch 930: 0.952878; Training Accuracy: 0.666461, Test Accuracy: 0.231670\n",
      "Cost after epoch 932: 0.984233; Training Accuracy: 0.633773, Test Accuracy: 0.246457\n",
      "Cost after epoch 934: 0.979178; Training Accuracy: 0.692281, Test Accuracy: 0.256315\n",
      "Cost after epoch 936: 0.942771; Training Accuracy: 0.673397, Test Accuracy: 0.250154\n",
      "Cost after epoch 938: 0.930700; Training Accuracy: 0.724694, Test Accuracy: 0.226741\n",
      "Cost after epoch 940: 0.948505; Training Accuracy: 0.672160, Test Accuracy: 0.235983\n",
      "Cost after epoch 942: 0.969239; Training Accuracy: 0.676418, Test Accuracy: 0.231054\n",
      "Cost after epoch 944: 0.918924; Training Accuracy: 0.698736, Test Accuracy: 0.253851\n",
      "Cost after epoch 946: 0.938485; Training Accuracy: 0.713295, Test Accuracy: 0.240912\n",
      "Cost after epoch 948: 0.985472; Training Accuracy: 0.649224, Test Accuracy: 0.255083\n",
      "Cost after epoch 950: 0.934297; Training Accuracy: 0.654100, Test Accuracy: 0.258164\n",
      "Cost after epoch 952: 0.929949; Training Accuracy: 0.708213, Test Accuracy: 0.215650\n",
      "Cost after epoch 954: 0.930127; Training Accuracy: 0.668177, Test Accuracy: 0.238447\n",
      "Cost after epoch 956: 0.952544; Training Accuracy: 0.721467, Test Accuracy: 0.243993\n",
      "Cost after epoch 958: 0.923631; Training Accuracy: 0.715836, Test Accuracy: 0.241528\n",
      "Cost after epoch 960: 0.916634; Training Accuracy: 0.719407, Test Accuracy: 0.210721\n",
      "Cost after epoch 962: 0.929718; Training Accuracy: 0.682942, Test Accuracy: 0.229205\n",
      "Cost after epoch 964: 0.975135; Training Accuracy: 0.694204, Test Accuracy: 0.241528\n",
      "Cost after epoch 966: 0.919978; Training Accuracy: 0.687406, Test Accuracy: 0.255083\n",
      "Cost after epoch 968: 0.971949; Training Accuracy: 0.616193, Test Accuracy: 0.208256\n",
      "Cost after epoch 970: 0.936895; Training Accuracy: 0.703887, Test Accuracy: 0.250154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 972: 0.965272; Training Accuracy: 0.642219, Test Accuracy: 0.268022\n",
      "Cost after epoch 974: 0.951237; Training Accuracy: 0.710754, Test Accuracy: 0.227357\n",
      "Cost after epoch 976: 0.966644; Training Accuracy: 0.684590, Test Accuracy: 0.243376\n",
      "Cost after epoch 978: 0.967581; Training Accuracy: 0.654374, Test Accuracy: 0.225508\n",
      "Cost after epoch 980: 0.966890; Training Accuracy: 0.663027, Test Accuracy: 0.247073\n",
      "Cost after epoch 982: 0.946978; Training Accuracy: 0.710548, Test Accuracy: 0.232902\n",
      "Cost after epoch 984: 0.909796; Training Accuracy: 0.687268, Test Accuracy: 0.216882\n",
      "Cost after epoch 986: 0.926988; Training Accuracy: 0.679096, Test Accuracy: 0.222428\n",
      "Cost after epoch 988: 0.934824; Training Accuracy: 0.693655, Test Accuracy: 0.250154\n",
      "Cost after epoch 990: 0.919638; Training Accuracy: 0.647988, Test Accuracy: 0.237215\n",
      "Cost after epoch 992: 0.925438; Training Accuracy: 0.728265, Test Accuracy: 0.234134\n",
      "Cost after epoch 994: 0.942480; Training Accuracy: 0.706840, Test Accuracy: 0.244609\n",
      "Cost after epoch 996: 0.973622; Training Accuracy: 0.703475, Test Accuracy: 0.215034\n",
      "Cost after epoch 998: 0.907442; Training Accuracy: 0.684659, Test Accuracy: 0.231670\n",
      "Cost after epoch 1000: 0.901392; Training Accuracy: 0.709655, Test Accuracy: 0.243993\n",
      "Cost after epoch 1002: 0.914238; Training Accuracy: 0.690221, Test Accuracy: 0.254467\n",
      "Cost after epoch 1004: 0.965949; Training Accuracy: 0.677517, Test Accuracy: 0.206408\n",
      "Cost after epoch 1006: 0.926323; Training Accuracy: 0.712471, Test Accuracy: 0.237215\n",
      "Cost after epoch 1008: 0.895067; Training Accuracy: 0.699286, Test Accuracy: 0.260012\n",
      "Cost after epoch 1010: 0.898123; Training Accuracy: 0.728883, Test Accuracy: 0.232286\n",
      "Cost after epoch 1012: 0.916519; Training Accuracy: 0.702101, Test Accuracy: 0.229205\n",
      "Cost after epoch 1014: 0.982540; Training Accuracy: 0.694479, Test Accuracy: 0.238447\n",
      "Cost after epoch 1016: 0.920483; Training Accuracy: 0.708282, Test Accuracy: 0.248306\n",
      "Cost after epoch 1018: 0.921519; Training Accuracy: 0.707389, Test Accuracy: 0.231054\n",
      "Cost after epoch 1020: 0.911879; Training Accuracy: 0.724900, Test Accuracy: 0.219963\n",
      "Cost after epoch 1022: 0.896985; Training Accuracy: 0.718171, Test Accuracy: 0.251386\n",
      "Cost after epoch 1024: 0.944906; Training Accuracy: 0.716866, Test Accuracy: 0.213185\n",
      "Cost after epoch 1026: 0.930593; Training Accuracy: 0.667285, Test Accuracy: 0.202711\n",
      "Cost after epoch 1028: 0.945397; Training Accuracy: 0.705604, Test Accuracy: 0.239063\n",
      "Cost after epoch 1030: 0.910401; Training Accuracy: 0.712196, Test Accuracy: 0.221811\n",
      "Cost after epoch 1032: 0.931118; Training Accuracy: 0.672572, Test Accuracy: 0.248922\n",
      "Cost after epoch 1034: 1.034449; Training Accuracy: 0.625532, Test Accuracy: 0.270487\n",
      "Cost after epoch 1036: 0.958732; Training Accuracy: 0.689191, Test Accuracy: 0.217498\n",
      "Cost after epoch 1038: 0.919206; Training Accuracy: 0.690358, Test Accuracy: 0.252619\n",
      "Cost after epoch 1040: 0.896754; Training Accuracy: 0.715767, Test Accuracy: 0.211337\n",
      "Cost after epoch 1042: 0.884629; Training Accuracy: 0.700522, Test Accuracy: 0.233518\n",
      "Cost after epoch 1044: 0.902053; Training Accuracy: 0.699904, Test Accuracy: 0.223660\n",
      "Cost after epoch 1046: 0.904292; Training Accuracy: 0.680470, Test Accuracy: 0.222428\n",
      "Cost after epoch 1048: 0.916102; Training Accuracy: 0.577050, Test Accuracy: 0.168207\n",
      "Cost after epoch 1050: 0.970877; Training Accuracy: 0.672916, Test Accuracy: 0.215034\n",
      "Cost after epoch 1052: 0.940465; Training Accuracy: 0.703337, Test Accuracy: 0.245225\n",
      "Cost after epoch 1054: 0.912667; Training Accuracy: 0.694822, Test Accuracy: 0.217498\n",
      "Cost after epoch 1056: 0.902395; Training Accuracy: 0.627936, Test Accuracy: 0.227973\n",
      "Cost after epoch 1058: 0.912314; Training Accuracy: 0.668795, Test Accuracy: 0.260628\n",
      "Cost after epoch 1060: 0.956150; Training Accuracy: 0.730875, Test Accuracy: 0.229205\n",
      "Cost after epoch 1062: 1.001572; Training Accuracy: 0.723390, Test Accuracy: 0.226124\n",
      "Cost after epoch 1064: 0.904751; Training Accuracy: 0.714462, Test Accuracy: 0.238447\n",
      "Cost after epoch 1066: 0.884060; Training Accuracy: 0.708900, Test Accuracy: 0.237831\n",
      "Cost after epoch 1068: 0.936842; Training Accuracy: 0.703955, Test Accuracy: 0.227973\n",
      "Cost after epoch 1070: 0.892366; Training Accuracy: 0.739253, Test Accuracy: 0.221195\n",
      "Cost after epoch 1072: 0.892496; Training Accuracy: 0.698324, Test Accuracy: 0.217498\n",
      "Cost after epoch 1074: 0.947455; Training Accuracy: 0.701621, Test Accuracy: 0.205176\n",
      "Cost after epoch 1076: 0.913792; Training Accuracy: 0.680126, Test Accuracy: 0.207024\n",
      "Cost after epoch 1078: 0.906715; Training Accuracy: 0.695646, Test Accuracy: 0.195317\n",
      "Cost after epoch 1080: 0.881870; Training Accuracy: 0.713707, Test Accuracy: 0.223660\n",
      "Cost after epoch 1082: 0.900282; Training Accuracy: 0.725724, Test Accuracy: 0.218115\n",
      "Cost after epoch 1084: 0.910992; Training Accuracy: 0.684453, Test Accuracy: 0.235367\n",
      "Cost after epoch 1086: 0.958727; Training Accuracy: 0.675663, Test Accuracy: 0.225508\n",
      "Cost after epoch 1088: 0.884284; Training Accuracy: 0.724145, Test Accuracy: 0.231054\n",
      "Cost after epoch 1090: 0.933704; Training Accuracy: 0.676624, Test Accuracy: 0.219347\n",
      "Cost after epoch 1092: 0.869199; Training Accuracy: 0.735064, Test Accuracy: 0.229821\n",
      "Cost after epoch 1094: 0.900949; Training Accuracy: 0.717690, Test Accuracy: 0.227357\n",
      "Cost after epoch 1096: 0.890641; Training Accuracy: 0.688024, Test Accuracy: 0.237831\n",
      "Cost after epoch 1098: 0.893979; Training Accuracy: 0.710067, Test Accuracy: 0.204559\n",
      "Cost after epoch 1100: 0.899204; Training Accuracy: 0.719475, Test Accuracy: 0.215034\n",
      "Cost after epoch 1102: 0.927093; Training Accuracy: 0.694204, Test Accuracy: 0.245841\n",
      "Cost after epoch 1104: 0.887798; Training Accuracy: 0.666804, Test Accuracy: 0.205176\n",
      "Cost after epoch 1106: 0.918205; Training Accuracy: 0.688230, Test Accuracy: 0.258780\n",
      "Cost after epoch 1108: 0.921829; Training Accuracy: 0.723184, Test Accuracy: 0.243993\n",
      "Cost after epoch 1110: 0.911135; Training Accuracy: 0.679714, Test Accuracy: 0.211953\n",
      "Cost after epoch 1112: 0.911974; Training Accuracy: 0.678135, Test Accuracy: 0.255083\n",
      "Cost after epoch 1114: 0.880000; Training Accuracy: 0.716385, Test Accuracy: 0.245841\n",
      "Cost after epoch 1116: 0.866763; Training Accuracy: 0.714256, Test Accuracy: 0.246457\n",
      "Cost after epoch 1118: 0.907543; Training Accuracy: 0.667353, Test Accuracy: 0.243376\n",
      "Cost after epoch 1120: 0.910045; Training Accuracy: 0.711509, Test Accuracy: 0.232902\n",
      "Cost after epoch 1122: 0.889908; Training Accuracy: 0.711853, Test Accuracy: 0.233518\n",
      "Cost after epoch 1124: 0.906380; Training Accuracy: 0.707458, Test Accuracy: 0.219963\n",
      "Cost after epoch 1126: 0.864255; Training Accuracy: 0.692350, Test Accuracy: 0.232286\n",
      "Cost after epoch 1128: 0.919198; Training Accuracy: 0.694135, Test Accuracy: 0.221811\n",
      "Cost after epoch 1130: 0.866491; Training Accuracy: 0.731081, Test Accuracy: 0.208872\n",
      "Cost after epoch 1132: 0.931506; Training Accuracy: 0.687818, Test Accuracy: 0.240912\n",
      "Cost after epoch 1134: 0.926622; Training Accuracy: 0.724488, Test Accuracy: 0.224892\n",
      "Cost after epoch 1136: 0.894543; Training Accuracy: 0.702925, Test Accuracy: 0.236599\n",
      "Cost after epoch 1138: 0.862800; Training Accuracy: 0.709999, Test Accuracy: 0.229821\n",
      "Cost after epoch 1140: 0.898880; Training Accuracy: 0.709175, Test Accuracy: 0.218731\n",
      "Cost after epoch 1142: 0.880779; Training Accuracy: 0.701552, Test Accuracy: 0.242760\n",
      "Cost after epoch 1144: 0.891979; Training Accuracy: 0.657533, Test Accuracy: 0.240912\n",
      "Cost after epoch 1146: 0.975642; Training Accuracy: 0.725999, Test Accuracy: 0.242144\n",
      "Cost after epoch 1148: 0.898743; Training Accuracy: 0.702513, Test Accuracy: 0.235367\n",
      "Cost after epoch 1150: 0.877176; Training Accuracy: 0.678410, Test Accuracy: 0.235983\n",
      "Cost after epoch 1152: 0.896501; Training Accuracy: 0.729089, Test Accuracy: 0.219347\n",
      "Cost after epoch 1154: 0.891580; Training Accuracy: 0.636245, Test Accuracy: 0.192853\n",
      "Cost after epoch 1156: 0.997555; Training Accuracy: 0.710548, Test Accuracy: 0.195933\n",
      "Cost after epoch 1158: 0.906781; Training Accuracy: 0.713020, Test Accuracy: 0.223044\n",
      "Cost after epoch 1160: 0.916145; Training Accuracy: 0.686307, Test Accuracy: 0.234134\n",
      "Cost after epoch 1162: 0.926016; Training Accuracy: 0.686856, Test Accuracy: 0.224892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 1164: 0.896076; Training Accuracy: 0.710205, Test Accuracy: 0.205792\n",
      "Cost after epoch 1166: 0.921819; Training Accuracy: 0.615163, Test Accuracy: 0.249538\n",
      "Cost after epoch 1168: 0.906158; Training Accuracy: 0.642975, Test Accuracy: 0.225508\n",
      "Cost after epoch 1170: 0.917582; Training Accuracy: 0.711509, Test Accuracy: 0.217498\n",
      "Cost after epoch 1172: 0.914523; Training Accuracy: 0.731218, Test Accuracy: 0.230437\n",
      "Cost after epoch 1174: 0.983974; Training Accuracy: 0.694479, Test Accuracy: 0.227973\n",
      "Cost after epoch 1176: 0.925732; Training Accuracy: 0.727716, Test Accuracy: 0.244609\n",
      "Cost after epoch 1178: 0.853881; Training Accuracy: 0.749828, Test Accuracy: 0.211953\n",
      "Cost after epoch 1180: 0.887106; Training Accuracy: 0.744403, Test Accuracy: 0.240296\n",
      "Cost after epoch 1182: 0.876320; Training Accuracy: 0.741038, Test Accuracy: 0.231054\n",
      "Cost after epoch 1184: 0.911783; Training Accuracy: 0.670581, Test Accuracy: 0.241528\n",
      "Cost after epoch 1186: 0.914446; Training Accuracy: 0.692350, Test Accuracy: 0.212569\n",
      "Cost after epoch 1188: 0.937960; Training Accuracy: 0.658014, Test Accuracy: 0.246457\n",
      "Cost after epoch 1190: 0.860484; Training Accuracy: 0.721604, Test Accuracy: 0.232286\n",
      "Cost after epoch 1192: 0.910347; Training Accuracy: 0.699973, Test Accuracy: 0.238447\n",
      "Cost after epoch 1194: 0.878355; Training Accuracy: 0.695852, Test Accuracy: 0.194085\n",
      "Cost after epoch 1196: 0.920535; Training Accuracy: 0.680332, Test Accuracy: 0.253235\n",
      "Cost after epoch 1198: 0.892199; Training Accuracy: 0.706153, Test Accuracy: 0.216266\n",
      "Cost after epoch 1200: 0.842915; Training Accuracy: 0.740970, Test Accuracy: 0.237831\n",
      "Cost after epoch 1202: 0.901233; Training Accuracy: 0.730463, Test Accuracy: 0.205792\n",
      "Cost after epoch 1204: 0.978116; Training Accuracy: 0.679989, Test Accuracy: 0.223044\n",
      "Cost after epoch 1206: 1.274106; Training Accuracy: 0.684659, Test Accuracy: 0.187924\n",
      "Cost after epoch 1208: 0.908465; Training Accuracy: 0.727716, Test Accuracy: 0.239063\n",
      "Cost after epoch 1210: 0.842408; Training Accuracy: 0.619832, Test Accuracy: 0.181146\n",
      "Cost after epoch 1212: 0.866313; Training Accuracy: 0.728197, Test Accuracy: 0.232902\n",
      "Cost after epoch 1214: 0.857561; Training Accuracy: 0.725656, Test Accuracy: 0.238447\n",
      "Cost after epoch 1216: 0.863225; Training Accuracy: 0.673877, Test Accuracy: 0.176833\n",
      "Cost after epoch 1218: 0.881960; Training Accuracy: 0.730188, Test Accuracy: 0.235983\n",
      "Cost after epoch 1220: 0.876187; Training Accuracy: 0.672160, Test Accuracy: 0.223660\n",
      "Cost after epoch 1222: 1.919255; Training Accuracy: 0.605411, Test Accuracy: 0.201479\n",
      "Cost after epoch 1224: 0.920601; Training Accuracy: 0.691045, Test Accuracy: 0.204559\n",
      "Cost after epoch 1226: 0.864333; Training Accuracy: 0.713982, Test Accuracy: 0.254467\n",
      "Cost after epoch 1228: 0.894508; Training Accuracy: 0.540791, Test Accuracy: 0.171288\n",
      "Cost after epoch 1230: 0.830761; Training Accuracy: 0.714325, Test Accuracy: 0.246457\n",
      "Cost after epoch 1232: 0.852604; Training Accuracy: 0.703063, Test Accuracy: 0.218731\n",
      "Cost after epoch 1234: 0.900513; Training Accuracy: 0.677448, Test Accuracy: 0.232286\n",
      "Cost after epoch 1236: 0.945648; Training Accuracy: 0.666941, Test Accuracy: 0.263709\n",
      "Cost after epoch 1238: 0.872883; Training Accuracy: 0.717759, Test Accuracy: 0.227357\n",
      "Cost after epoch 1240: 0.894513; Training Accuracy: 0.683423, Test Accuracy: 0.227357\n",
      "Cost after epoch 1242: 0.919559; Training Accuracy: 0.714394, Test Accuracy: 0.225508\n",
      "Cost after epoch 1244: 0.970770; Training Accuracy: 0.705604, Test Accuracy: 0.245225\n",
      "Cost after epoch 1246: 0.929971; Training Accuracy: 0.699973, Test Accuracy: 0.249538\n",
      "Cost after epoch 1248: 0.893468; Training Accuracy: 0.690427, Test Accuracy: 0.198398\n",
      "Cost after epoch 1250: 0.875884; Training Accuracy: 0.744815, Test Accuracy: 0.232902\n",
      "Cost after epoch 1252: 1.140655; Training Accuracy: 0.677792, Test Accuracy: 0.207640\n",
      "Cost after epoch 1254: 1.282937; Training Accuracy: 0.696264, Test Accuracy: 0.237831\n",
      "Cost after epoch 1256: 0.862731; Training Accuracy: 0.681088, Test Accuracy: 0.206408\n",
      "Cost after epoch 1258: 0.857262; Training Accuracy: 0.756764, Test Accuracy: 0.212569\n",
      "Cost after epoch 1260: 0.822598; Training Accuracy: 0.741656, Test Accuracy: 0.229821\n",
      "Cost after epoch 1262: 1.029452; Training Accuracy: 0.672366, Test Accuracy: 0.261245\n",
      "Cost after epoch 1264: 0.993607; Training Accuracy: 0.616330, Test Accuracy: 0.247689\n",
      "Cost after epoch 1266: 0.844603; Training Accuracy: 0.749966, Test Accuracy: 0.231670\n",
      "Cost after epoch 1268: 0.835367; Training Accuracy: 0.706496, Test Accuracy: 0.237831\n",
      "Cost after epoch 1270: 0.845793; Training Accuracy: 0.724626, Test Accuracy: 0.195933\n",
      "Cost after epoch 1272: 0.883227; Training Accuracy: 0.721055, Test Accuracy: 0.239680\n",
      "Cost after epoch 1274: 0.928118; Training Accuracy: 0.721055, Test Accuracy: 0.231054\n",
      "Cost after epoch 1276: 0.826170; Training Accuracy: 0.702445, Test Accuracy: 0.245841\n",
      "Cost after epoch 1278: 0.857136; Training Accuracy: 0.708076, Test Accuracy: 0.236599\n",
      "Cost after epoch 1280: 0.918830; Training Accuracy: 0.702994, Test Accuracy: 0.203327\n",
      "Cost after epoch 1282: 0.887505; Training Accuracy: 0.732935, Test Accuracy: 0.229205\n",
      "Cost after epoch 1284: 0.828746; Training Accuracy: 0.676212, Test Accuracy: 0.247073\n",
      "Cost after epoch 1286: 0.904060; Training Accuracy: 0.712883, Test Accuracy: 0.219347\n",
      "Cost after epoch 1288: 1.248753; Training Accuracy: 0.654924, Test Accuracy: 0.218731\n",
      "Cost after epoch 1290: 0.963330; Training Accuracy: 0.697500, Test Accuracy: 0.225508\n",
      "Cost after epoch 1292: 0.885432; Training Accuracy: 0.736643, Test Accuracy: 0.226124\n",
      "Cost after epoch 1294: 0.836593; Training Accuracy: 0.680950, Test Accuracy: 0.247073\n",
      "Cost after epoch 1296: 0.822039; Training Accuracy: 0.740008, Test Accuracy: 0.236599\n",
      "Cost after epoch 1298: 0.855259; Training Accuracy: 0.678135, Test Accuracy: 0.181146\n",
      "Cost after epoch 1300: 0.880305; Training Accuracy: 0.673328, Test Accuracy: 0.212569\n",
      "Cost after epoch 1302: 0.832330; Training Accuracy: 0.715424, Test Accuracy: 0.250154\n",
      "Cost after epoch 1304: 0.870598; Training Accuracy: 0.699767, Test Accuracy: 0.200246\n",
      "Cost after epoch 1306: 0.879005; Training Accuracy: 0.653138, Test Accuracy: 0.250770\n",
      "Cost after epoch 1308: 0.866147; Training Accuracy: 0.735476, Test Accuracy: 0.217498\n",
      "Cost after epoch 1310: 0.844753; Training Accuracy: 0.703406, Test Accuracy: 0.232902\n",
      "Cost after epoch 1312: 0.865313; Training Accuracy: 0.694067, Test Accuracy: 0.227357\n",
      "Cost after epoch 1314: 0.907489; Training Accuracy: 0.689122, Test Accuracy: 0.236599\n",
      "Cost after epoch 1316: 0.877311; Training Accuracy: 0.711441, Test Accuracy: 0.216882\n",
      "Cost after epoch 1318: 0.868359; Training Accuracy: 0.740008, Test Accuracy: 0.215650\n",
      "Cost after epoch 1320: 0.861349; Training Accuracy: 0.690633, Test Accuracy: 0.199014\n",
      "Cost after epoch 1322: 0.875177; Training Accuracy: 0.714600, Test Accuracy: 0.243376\n",
      "Cost after epoch 1324: 0.895968; Training Accuracy: 0.662684, Test Accuracy: 0.237215\n",
      "Cost after epoch 1326: 0.912963; Training Accuracy: 0.705741, Test Accuracy: 0.195933\n",
      "Cost after epoch 1328: 0.980462; Training Accuracy: 0.658220, Test Accuracy: 0.273567\n",
      "Cost after epoch 1330: 0.852002; Training Accuracy: 0.744747, Test Accuracy: 0.231670\n",
      "Cost after epoch 1332: 0.925001; Training Accuracy: 0.692419, Test Accuracy: 0.253851\n",
      "Cost after epoch 1334: 0.864658; Training Accuracy: 0.727098, Test Accuracy: 0.224276\n",
      "Cost after epoch 1336: 0.867192; Training Accuracy: 0.713158, Test Accuracy: 0.240912\n",
      "Cost after epoch 1338: 0.866514; Training Accuracy: 0.722291, Test Accuracy: 0.225508\n",
      "Cost after epoch 1340: 0.864484; Training Accuracy: 0.696402, Test Accuracy: 0.196550\n",
      "Cost after epoch 1342: 0.829869; Training Accuracy: 0.722978, Test Accuracy: 0.238447\n",
      "Cost after epoch 1344: 0.849592; Training Accuracy: 0.712127, Test Accuracy: 0.213185\n",
      "Cost after epoch 1346: 0.924113; Training Accuracy: 0.707595, Test Accuracy: 0.245841\n",
      "Cost after epoch 1348: 0.853345; Training Accuracy: 0.720505, Test Accuracy: 0.206408\n",
      "Cost after epoch 1350: 0.887002; Training Accuracy: 0.736575, Test Accuracy: 0.235983\n",
      "Cost after epoch 1352: 0.887069; Training Accuracy: 0.702857, Test Accuracy: 0.253235\n",
      "Cost after epoch 1354: 0.995159; Training Accuracy: 0.686101, Test Accuracy: 0.218115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 1356: 1.145222; Training Accuracy: 0.693037, Test Accuracy: 0.196550\n",
      "Cost after epoch 1358: 0.889499; Training Accuracy: 0.694479, Test Accuracy: 0.227357\n",
      "Cost after epoch 1360: 1.074399; Training Accuracy: 0.692350, Test Accuracy: 0.241528\n",
      "Cost after epoch 1362: 0.856211; Training Accuracy: 0.721810, Test Accuracy: 0.199630\n",
      "Cost after epoch 1364: 0.823178; Training Accuracy: 0.734995, Test Accuracy: 0.227973\n",
      "Cost after epoch 1366: 1.166491; Training Accuracy: 0.724420, Test Accuracy: 0.209489\n",
      "Cost after epoch 1368: 0.835873; Training Accuracy: 0.700110, Test Accuracy: 0.222428\n",
      "Cost after epoch 1370: 0.872042; Training Accuracy: 0.701483, Test Accuracy: 0.257548\n",
      "Cost after epoch 1372: 0.850848; Training Accuracy: 0.728197, Test Accuracy: 0.241528\n",
      "Cost after epoch 1374: 0.835343; Training Accuracy: 0.683560, Test Accuracy: 0.240912\n",
      "Cost after epoch 1376: 0.891861; Training Accuracy: 0.702239, Test Accuracy: 0.240912\n",
      "Cost after epoch 1378: 0.996262; Training Accuracy: 0.690496, Test Accuracy: 0.260012\n",
      "Cost after epoch 1380: 0.996304; Training Accuracy: 0.639267, Test Accuracy: 0.173752\n",
      "Cost after epoch 1382: 0.829903; Training Accuracy: 0.751682, Test Accuracy: 0.226124\n",
      "Cost after epoch 1384: 1.315358; Training Accuracy: 0.696333, Test Accuracy: 0.232902\n",
      "Cost after epoch 1386: 0.801900; Training Accuracy: 0.729913, Test Accuracy: 0.247073\n",
      "Cost after epoch 1388: 0.912013; Training Accuracy: 0.712608, Test Accuracy: 0.250154\n",
      "Cost after epoch 1390: 1.038162; Training Accuracy: 0.653619, Test Accuracy: 0.219963\n",
      "Cost after epoch 1392: 1.729213; Training Accuracy: 0.645241, Test Accuracy: 0.224276\n",
      "Cost after epoch 1394: 0.862449; Training Accuracy: 0.727235, Test Accuracy: 0.237831\n",
      "Cost after epoch 1396: 0.871022; Training Accuracy: 0.753537, Test Accuracy: 0.208256\n",
      "Cost after epoch 1398: 0.890314; Training Accuracy: 0.724008, Test Accuracy: 0.240912\n",
      "Cost after epoch 1400: 0.934658; Training Accuracy: 0.723527, Test Accuracy: 0.215034\n",
      "Cost after epoch 1402: 0.887053; Training Accuracy: 0.715424, Test Accuracy: 0.232902\n",
      "Cost after epoch 1404: 0.863761; Training Accuracy: 0.730738, Test Accuracy: 0.234134\n",
      "Cost after epoch 1406: 0.885002; Training Accuracy: 0.711990, Test Accuracy: 0.258164\n",
      "Cost after epoch 1408: 0.814700; Training Accuracy: 0.713707, Test Accuracy: 0.214418\n",
      "Cost after epoch 1410: 0.851159; Training Accuracy: 0.746944, Test Accuracy: 0.211953\n",
      "Cost after epoch 1412: 0.876998; Training Accuracy: 0.757314, Test Accuracy: 0.228589\n",
      "Cost after epoch 1414: 0.885221; Training Accuracy: 0.719681, Test Accuracy: 0.216882\n",
      "Cost after epoch 1416: 0.952475; Training Accuracy: 0.654580, Test Accuracy: 0.229205\n",
      "Cost after epoch 1418: 1.799395; Training Accuracy: 0.611935, Test Accuracy: 0.184227\n",
      "Cost after epoch 1420: 1.109877; Training Accuracy: 0.727853, Test Accuracy: 0.208872\n",
      "Cost after epoch 1422: 0.806405; Training Accuracy: 0.731768, Test Accuracy: 0.218115\n",
      "Cost after epoch 1424: 0.825312; Training Accuracy: 0.739459, Test Accuracy: 0.235983\n",
      "Cost after epoch 1426: 0.828665; Training Accuracy: 0.685826, Test Accuracy: 0.243993\n",
      "Cost after epoch 1428: 0.924204; Training Accuracy: 0.742068, Test Accuracy: 0.188540\n",
      "Cost after epoch 1430: 0.856536; Training Accuracy: 0.698599, Test Accuracy: 0.200863\n",
      "Cost after epoch 1432: 0.833879; Training Accuracy: 0.633773, Test Accuracy: 0.208256\n",
      "Cost after epoch 1434: 0.833553; Training Accuracy: 0.724282, Test Accuracy: 0.191620\n",
      "Cost after epoch 1436: 0.853810; Training Accuracy: 0.705947, Test Accuracy: 0.243993\n",
      "Cost after epoch 1438: 0.887972; Training Accuracy: 0.735064, Test Accuracy: 0.221195\n",
      "Cost after epoch 1440: 1.327810; Training Accuracy: 0.705810, Test Accuracy: 0.226741\n",
      "Cost after epoch 1442: 0.830188; Training Accuracy: 0.711921, Test Accuracy: 0.216266\n",
      "Cost after epoch 1444: 0.836108; Training Accuracy: 0.693998, Test Accuracy: 0.218731\n",
      "Cost after epoch 1446: 0.802844; Training Accuracy: 0.722497, Test Accuracy: 0.242144\n",
      "Cost after epoch 1448: 0.884802; Training Accuracy: 0.717003, Test Accuracy: 0.233518\n",
      "Cost after epoch 1450: 0.880422; Training Accuracy: 0.749142, Test Accuracy: 0.242760\n",
      "Cost after epoch 1452: 0.812067; Training Accuracy: 0.752163, Test Accuracy: 0.211953\n",
      "Cost after epoch 1454: 0.814712; Training Accuracy: 0.698393, Test Accuracy: 0.231054\n",
      "Cost after epoch 1456: 0.839525; Training Accuracy: 0.711715, Test Accuracy: 0.219963\n",
      "Cost after epoch 1458: 1.132883; Training Accuracy: 0.688436, Test Accuracy: 0.195933\n",
      "Cost after epoch 1460: 0.906805; Training Accuracy: 0.694822, Test Accuracy: 0.197782\n",
      "Cost after epoch 1462: 1.142872; Training Accuracy: 0.669345, Test Accuracy: 0.212569\n",
      "Cost after epoch 1464: 0.801243; Training Accuracy: 0.768438, Test Accuracy: 0.215034\n",
      "Cost after epoch 1466: 0.820044; Training Accuracy: 0.727167, Test Accuracy: 0.182994\n",
      "Cost after epoch 1468: 0.839840; Training Accuracy: 0.701621, Test Accuracy: 0.191004\n",
      "Cost after epoch 1470: 0.786424; Training Accuracy: 0.770911, Test Accuracy: 0.231670\n",
      "Cost after epoch 1472: 0.864654; Training Accuracy: 0.752438, Test Accuracy: 0.222428\n",
      "Cost after epoch 1474: 0.836600; Training Accuracy: 0.713501, Test Accuracy: 0.229821\n",
      "Cost after epoch 1476: 0.847024; Training Accuracy: 0.655611, Test Accuracy: 0.224276\n",
      "Cost after epoch 1478: 1.062144; Training Accuracy: 0.553564, Test Accuracy: 0.254467\n",
      "Cost after epoch 1480: 0.890606; Training Accuracy: 0.694547, Test Accuracy: 0.203327\n",
      "Cost after epoch 1482: 0.811222; Training Accuracy: 0.726480, Test Accuracy: 0.214418\n",
      "Cost after epoch 1484: 0.803456; Training Accuracy: 0.672778, Test Accuracy: 0.227973\n",
      "Cost after epoch 1486: 0.831586; Training Accuracy: 0.728128, Test Accuracy: 0.229205\n",
      "Cost after epoch 1488: 1.039962; Training Accuracy: 0.504532, Test Accuracy: 0.194085\n",
      "Cost after epoch 1490: 2.774065; Training Accuracy: 0.484549, Test Accuracy: 0.266174\n",
      "Cost after epoch 1492: 0.923982; Training Accuracy: 0.725450, Test Accuracy: 0.215034\n",
      "Cost after epoch 1494: 0.788527; Training Accuracy: 0.724145, Test Accuracy: 0.243993\n",
      "Cost after epoch 1496: 0.844543; Training Accuracy: 0.726617, Test Accuracy: 0.218731\n",
      "Cost after epoch 1498: 0.846159; Training Accuracy: 0.737536, Test Accuracy: 0.235983\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x32a4ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.728128\n",
      "Test Accuracy: 0.208872\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
